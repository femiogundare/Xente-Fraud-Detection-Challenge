{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold, StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('FeatureEngineeredTrain.csv')\n",
    "test_data = pd.read_csv('FeatureEngineeredTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PricingStrategy'] = train_data['PricingStrategy'].replace({0:1, 1:2, 2:3})\n",
    "test_data['PricingStrategy'] = test_data['PricingStrategy'].replace({0:1, 1:2, 2:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Charges_per_Pricing'] = train_data['ExtraCharges']/train_data['PricingStrategy']\n",
    "test_data['Charges_per_Pricing'] = test_data['ExtraCharges']/test_data['PricingStrategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_in_seconds(time_series):\n",
    "    time = time_series.split(' ')[1].split(':')\n",
    "    hr, mn, sec = int(time[0]), int(time[1]), int(time[2])\n",
    "    return hr*3600 + mn*60 + sec\n",
    "\n",
    "train_data['Time_in_Secs'] = train_data['Time'].map(time_in_seconds)\n",
    "test_data['Time_in_Secs'] = test_data['Time'].map(time_in_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Cyclic_Time_x'] = train_data['Time_in_Secs'].map(lambda x: math.sin(2*math.pi*x/86400))\n",
    "train_data['Cyclic_Time_y'] = train_data['Time_in_Secs'].map(lambda x: math.cos(2*math.pi*x/86400))\n",
    "\n",
    "test_data['Cyclic_Time_x'] = test_data['Time_in_Secs'].map(lambda x: math.sin(2*math.pi*x/86400))\n",
    "test_data['Cyclic_Time_y'] = test_data['Time_in_Secs'].map(lambda x: math.cos(2*math.pi*x/86400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_of_trans(time_series):\n",
    "    time = time_series.split('T')[0].split('-')\n",
    "    day = int(time[2])\n",
    "    \n",
    "    if day in range(1, 8):\n",
    "        return 'first_week'\n",
    "    elif day in range(8, 15):\n",
    "        return 'second_week'\n",
    "    elif day in range(15, 22):\n",
    "        return 'third_week'\n",
    "    elif day in range(22, 29):\n",
    "        return 'fourth_week'\n",
    "    else:\n",
    "        return 'fifth_week'\n",
    "    \n",
    "train_data['Week'] = train_data['TransactionStartTime'].map(week_of_trans)\n",
    "test_data['Week'] = test_data['TransactionStartTime'].map(week_of_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Amount_to_mean_CustomerId'] = train_data['Amount']/train_data.groupby('CustomerId')['Amount'].transform('mean')\n",
    "train_data['Amount_to_std_CustomerId'] = train_data['Amount']/train_data.groupby('CustomerId')['Amount'].transform('std')\n",
    "\n",
    "train_data['Amount_to_mean_ProviderId'] = train_data['Amount']/train_data.groupby('ProviderId')['Amount'].transform('mean')\n",
    "train_data['Amount_to_std_ProviderId'] = train_data['Amount']/train_data.groupby('ProviderId')['Amount'].transform('std')\n",
    "\n",
    "train_data['Amount_to_mean_PricingStrategy'] = train_data['Amount']/train_data.groupby('PricingStrategy')['Amount'].transform('mean')\n",
    "train_data['Amount_to_std_PricingStrategy'] = train_data['Amount']/train_data.groupby('PricingStrategy')['Amount'].transform('std')\n",
    "\n",
    "train_data['Amount_to_mean_ProductCategory'] = train_data['Amount']/train_data.groupby('ProductCategory')['Amount'].transform('mean')\n",
    "train_data['Amount_to_std_ProductCategory'] = train_data['Amount']/train_data.groupby('ProductCategory')['Amount'].transform('std')\n",
    "\n",
    "train_data['Amount_to_mean_ChannelId'] = train_data['Amount']/train_data.groupby('ChannelId')['Amount'].transform('mean')\n",
    "train_data['Amount_to_std_ChannelId'] = train_data['Amount']/train_data.groupby('ChannelId')['Amount'].transform('std')\n",
    "\n",
    "train_data['Amount_to_mean_ProductId'] = train_data['Amount']/train_data.groupby('ProductId')['Amount'].transform('mean')\n",
    "train_data['Amount_to_std_ProductId'] = train_data['Amount']/train_data.groupby('ProductId')['Amount'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.328699\n",
       "1   -0.006574\n",
       "2         inf\n",
       "3    1.164874\n",
       "4   -0.037509\n",
       "Name: Amount_to_std_CustomerId, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Amount_to_std_CustomerId'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Amount_to_mean_CustomerId'] = test_data['Amount']/test_data.groupby('CustomerId')['Amount'].transform('mean')\n",
    "test_data['Amount_to_std_CustomerId'] = test_data['Amount']/test_data.groupby('CustomerId')['Amount'].transform('std')\n",
    "\n",
    "test_data['Amount_to_mean_ProviderId'] = test_data['Amount']/test_data.groupby('ProviderId')['Amount'].transform('mean')\n",
    "test_data['Amount_to_std_ProviderId'] = test_data['Amount']/test_data.groupby('ProviderId')['Amount'].transform('std')\n",
    "\n",
    "test_data['Amount_to_mean_PricingStrategy'] = test_data['Amount']/test_data.groupby('PricingStrategy')['Amount'].transform('mean')\n",
    "test_data['Amount_to_std_PricingStrategy'] = test_data['Amount']/test_data.groupby('PricingStrategy')['Amount'].transform('std')\n",
    "\n",
    "test_data['Amount_to_mean_ProductCategory'] = test_data['Amount']/test_data.groupby('ProductCategory')['Amount'].transform('mean')\n",
    "test_data['Amount_to_std_ProductCategory'] = test_data['Amount']/test_data.groupby('ProductCategory')['Amount'].transform('std')\n",
    "\n",
    "test_data['Amount_to_mean_ChannelId'] = test_data['Amount']/test_data.groupby('ChannelId')['Amount'].transform('mean')\n",
    "test_data['Amount_to_std_ChannelId'] = test_data['Amount']/test_data.groupby('ChannelId')['Amount'].transform('std')\n",
    "\n",
    "test_data['Amount_to_mean_ProductId'] = test_data['Amount']/test_data.groupby('ProductId')['Amount'].transform('mean')\n",
    "test_data['Amount_to_std_ProductId'] = test_data['Amount']/test_data.groupby('ProductId')['Amount'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.replace([np.inf, -np.inf], np.nan)\n",
    "test_data = test_data.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    95662\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isin([np.inf, -np.inf, np.nan]).all(axis='columns').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = train_data.copy()\n",
    "original_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols = train_data.columns[np.where(train_data.isnull().sum()>0)]\n",
    "\n",
    "for col in null_cols:\n",
    "    train_data[col] = train_data[col].fillna(train_data[col].mean())\n",
    "    test_data[col] = test_data[col].fillna(test_data[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38230    46808\n",
       "Name: Time_in_Secs, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Time_in_Secs'].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2018-11-15 02:18:49\n",
       "1    2018-11-15 02:19:08\n",
       "2    2018-11-15 02:44:21\n",
       "3    2018-11-15 03:32:55\n",
       "4    2018-11-15 03:34:21\n",
       "Name: Time, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Time'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import i0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Time'] = pd.to_datetime(train_data['Time'])\n",
    "test_data['Time'] = pd.to_datetime(test_data['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Time_in_Secs'] = train_data['Time_in_Secs'].map(lambda x: 2*math.pi*x/86400)\n",
    "test_data['Time_in_Secs'] = test_data['Time_in_Secs'].map(lambda x: 2*math.pi*x/86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mn(array):\n",
    "    a = np.power(np.sum(np.cos(array)), 2)\n",
    "    b = np.power(np.sum(np.sin(array)), 2)\n",
    "    c = np.sum(np.cos(array))\n",
    "    d = np.sum(np.sin(array))\n",
    "    return 2*np.arctan(d/((np.sqrt(a+b) + c)))\n",
    "\n",
    "\n",
    "\n",
    "def std(array):\n",
    "    n = len(array)\n",
    "    a = np.power((np.sum(np.sin(array)))/n, 2)\n",
    "    b = np.power((np.sum(np.cos(array)))/n, 2)\n",
    "    return np.sqrt(np.log(1/(a+b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(df):\n",
    "    inv_std, time, mean, STD = df[0], df[1], df[2], df[3]\n",
    "    return np.exp(inv_std*np.cos(time - mean*STD))/(2*np.pi*i0(inv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#math.exp(inv_std*math.cos(t - mn*std))/(2*math.pi*i0(inv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "confidence_95 = 0.95\n",
    "confidence_90 = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_interval_95(array):\n",
    "    n = len(array)\n",
    "    m = mean(array)\n",
    "    std_err = sem(array)\n",
    "    h = std_err * t.ppf((1 + confidence_95) / 2, n - 1)\n",
    "\n",
    "    start = m - h\n",
    "    return start\n",
    "\n",
    "    \n",
    "def upper_interval_95(array):\n",
    "    n = len(array)\n",
    "    m = mean(array)\n",
    "    std_err = sem(array)\n",
    "    h = std_err * t.ppf((1 + confidence_95) / 2, n - 1)\n",
    "\n",
    "    end = m + h\n",
    "    return end\n",
    "    \n",
    "    \n",
    "    \n",
    "def lower_interval_90(array):\n",
    "    n = len(array)\n",
    "    m = mean(array)\n",
    "    std_err = sem(array)\n",
    "    h = std_err * t.ppf((1 + confidence_90) / 2, n - 1)\n",
    "\n",
    "    start = m - h\n",
    "    return start\n",
    "\n",
    "    \n",
    "def upper_interval_90(array):\n",
    "    n = len(array)\n",
    "    m = mean(array)\n",
    "    std_err = sem(array)\n",
    "    h = std_err * t.ppf((1 + confidence_90) / 2, n - 1)\n",
    "\n",
    "    end = m + h\n",
    "    return end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_7days_95 = train_data.set_index('Time').groupby('CustomerId').rolling('7d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_7days_95 = agg_func_7days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_7days_0.95', 'std' : 'std_7days_0.95'})\n",
    "train_data = pd.merge(train_data, agg_func_7days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['std_7days_0.95'] = train_data['std_7days_0.95'].fillna(0)\n",
    "train_data['inv_std_7days_0.95'] = 1/train_data['std_7days_0.95']\n",
    "train_data['inv_std_7days_0.95'] = train_data['inv_std_7days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "train_data['inv_std_7days_0.95'] = train_data['inv_std_7days_0.95'].fillna(0)\n",
    "\n",
    "train_data['vonmises_time_7days_0.95'] = train_data[['inv_std_7days_0.95', 'Time_in_Secs', 'mean_7days_0.95', 'std_7days_0.95']].apply(distribution, axis=1)\n",
    "train_data['vonmises_time_7days_0.95'].fillna(train_data['vonmises_time_7days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_7days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('7d')['vonmises_time_7days_0.95'].apply(lower_interval_95)\n",
    "low_7days_95 = low_7days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_7days_95 = low_7days_95.rename(columns={'vonmises_time_7days_0.95' : 'lower_interval_7days_0.95'})\n",
    "train_data = pd.merge(train_data, low_7days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_7days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('7d')['vonmises_time_7days_0.95'].apply(upper_interval_95)\n",
    "high_7days_95 = high_7days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_7days_95 = high_7days_95.rename(columns={'vonmises_time_7days_0.95' : 'upper_interval_7days_0.95'})\n",
    "train_data = pd.merge(train_data, high_7days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['lower_interval_7days_0.95'].fillna(train_data['lower_interval_7days_0.95'].mean(), inplace=True)\n",
    "train_data['upper_interval_7days_0.95'].fillna(train_data['upper_interval_7days_0.95'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Within_CI95_7days'] = train_data[['vonmises_time_7days_0.95', 'lower_interval_7days_0.95', 'upper_interval_7days_0.95']].apply(check, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['mean_7days_0.95', 'std_7days_0.95', 'inv_std_7days_0.95', 'vonmises_time_7days_0.95', 'lower_interval_7days_0.95', 'upper_interval_7days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_std_ProviderId', 'Amount_to_mean_PricingStrategy',\n",
       "       'Amount_to_std_PricingStrategy', 'Amount_to_mean_ProductCategory',\n",
       "       'Amount_to_std_ProductCategory', 'Amount_to_mean_ChannelId',\n",
       "       'Amount_to_std_ChannelId', 'Amount_to_mean_ProductId',\n",
       "       'Amount_to_std_ProductId', 'Within_CI95_7days'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    47925\n",
       "No     47737\n",
       "Name: Within_CI95_7days, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Within_CI95_7days'].value_counts()#.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_14days_95 = train_data.set_index('Time').groupby('CustomerId').rolling('14d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_14days_95 = agg_func_14days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_14days_0.95', 'std' : 'std_14days_0.95'})\n",
    "train_data = pd.merge(train_data, agg_func_14days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['std_14days_0.95'] = train_data['std_14days_0.95'].fillna(0)\n",
    "train_data['inv_std_14days_0.95'] = 1/train_data['std_14days_0.95']\n",
    "train_data['inv_std_14days_0.95'] = train_data['inv_std_14days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "train_data['inv_std_14days_0.95'] = train_data['inv_std_14days_0.95'].fillna(0)\n",
    "\n",
    "train_data['vonmises_time_14days_0.95'] = train_data[['inv_std_14days_0.95', 'Time_in_Secs', 'mean_14days_0.95', 'std_14days_0.95']].apply(distribution, axis=1)\n",
    "train_data['vonmises_time_14days_0.95'].fillna(train_data['vonmises_time_14days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_14days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('14d')['vonmises_time_14days_0.95'].apply(lower_interval_95)\n",
    "low_14days_95 = low_14days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_14days_95 = low_14days_95.rename(columns={'vonmises_time_14days_0.95' : 'lower_interval_14days_0.95'})\n",
    "train_data = pd.merge(train_data, low_14days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_14days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('14d')['vonmises_time_14days_0.95'].apply(upper_interval_95)\n",
    "high_14days_95 = high_14days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_14days_95 = high_14days_95.rename(columns={'vonmises_time_14days_0.95' : 'upper_interval_14days_0.95'})\n",
    "train_data = pd.merge(train_data, high_14days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['lower_interval_14days_0.95'].fillna(train_data['lower_interval_14days_0.95'].mean(), inplace=True)\n",
    "train_data['upper_interval_14days_0.95'].fillna(train_data['upper_interval_14days_0.95'].mean(), inplace=True)\n",
    "\n",
    "train_data['Within_CI95_14days'] = train_data[['vonmises_time_14days_0.95', 'lower_interval_14days_0.95', 'upper_interval_14days_0.95']].apply(check, axis=1)\n",
    "\n",
    "train_data.drop(['mean_14days_0.95', 'std_14days_0.95', 'inv_std_14days_0.95', 'vonmises_time_14days_0.95', 'lower_interval_14days_0.95', 'upper_interval_14days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_mean_PricingStrategy', 'Amount_to_std_PricingStrategy',\n",
       "       'Amount_to_mean_ProductCategory', 'Amount_to_std_ProductCategory',\n",
       "       'Amount_to_mean_ChannelId', 'Amount_to_std_ChannelId',\n",
       "       'Amount_to_mean_ProductId', 'Amount_to_std_ProductId',\n",
       "       'Within_CI95_7days', 'Within_CI95_14days'],\n",
       "      dtype='object', length=148)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     55670\n",
       "Yes    39992\n",
       "Name: Within_CI95_14days, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Within_CI95_14days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_21days_95 = train_data.set_index('Time').groupby('CustomerId').rolling('21d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_21days_95 = agg_func_21days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_21days_0.95', 'std' : 'std_21days_0.95'})\n",
    "train_data = pd.merge(train_data, agg_func_21days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['std_21days_0.95'] = train_data['std_21days_0.95'].fillna(0)\n",
    "train_data['inv_std_21days_0.95'] = 1/train_data['std_21days_0.95']\n",
    "train_data['inv_std_21days_0.95'] = train_data['inv_std_21days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "train_data['inv_std_21days_0.95'] = train_data['inv_std_21days_0.95'].fillna(0)\n",
    "\n",
    "train_data['vonmises_time_21days_0.95'] = train_data[['inv_std_21days_0.95', 'Time_in_Secs', 'mean_21days_0.95', 'std_21days_0.95']].apply(distribution, axis=1)\n",
    "train_data['vonmises_time_21days_0.95'].fillna(train_data['vonmises_time_21days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_21days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('21d')['vonmises_time_21days_0.95'].apply(lower_interval_95)\n",
    "low_21days_95 = low_21days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_21days_95 = low_21days_95.rename(columns={'vonmises_time_21days_0.95' : 'lower_interval_21days_0.95'})\n",
    "train_data = pd.merge(train_data, low_21days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_21days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('21d')['vonmises_time_21days_0.95'].apply(upper_interval_95)\n",
    "high_21days_95 = high_21days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_21days_95 = high_21days_95.rename(columns={'vonmises_time_21days_0.95' : 'upper_interval_21days_0.95'})\n",
    "train_data = pd.merge(train_data, high_21days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['lower_interval_21days_0.95'].fillna(train_data['lower_interval_21days_0.95'].mean(), inplace=True)\n",
    "train_data['upper_interval_21days_0.95'].fillna(train_data['upper_interval_21days_0.95'].mean(), inplace=True)\n",
    "\n",
    "train_data['Within_CI95_21days'] = train_data[['vonmises_time_21days_0.95', 'lower_interval_21days_0.95', 'upper_interval_21days_0.95']].apply(check, axis=1)\n",
    "\n",
    "train_data.drop(['mean_21days_0.95', 'std_21days_0.95', 'inv_std_21days_0.95', 'vonmises_time_21days_0.95', 'lower_interval_21days_0.95', 'upper_interval_21days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_std_PricingStrategy', 'Amount_to_mean_ProductCategory',\n",
       "       'Amount_to_std_ProductCategory', 'Amount_to_mean_ChannelId',\n",
       "       'Amount_to_std_ChannelId', 'Amount_to_mean_ProductId',\n",
       "       'Amount_to_std_ProductId', 'Within_CI95_7days', 'Within_CI95_14days',\n",
       "       'Within_CI95_21days'],\n",
       "      dtype='object', length=149)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     55670\n",
       "Yes    39992\n",
       "Name: Within_CI95_14days, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Within_CI95_14days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_28days_95 = train_data.set_index('Time').groupby('CustomerId').rolling('28d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_28days_95 = agg_func_28days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_28days_0.95', 'std' : 'std_28days_0.95'})\n",
    "train_data = pd.merge(train_data, agg_func_28days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['std_28days_0.95'] = train_data['std_28days_0.95'].fillna(0)\n",
    "train_data['inv_std_28days_0.95'] = 1/train_data['std_28days_0.95']\n",
    "train_data['inv_std_28days_0.95'] = train_data['inv_std_28days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "train_data['inv_std_28days_0.95'] = train_data['inv_std_28days_0.95'].fillna(0)\n",
    "\n",
    "train_data['vonmises_time_28days_0.95'] = train_data[['inv_std_28days_0.95', 'Time_in_Secs', 'mean_28days_0.95', 'std_28days_0.95']].apply(distribution, axis=1)\n",
    "train_data['vonmises_time_28days_0.95'].fillna(train_data['vonmises_time_28days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_28days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('28d')['vonmises_time_28days_0.95'].apply(lower_interval_95)\n",
    "low_28days_95 = low_28days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_28days_95 = low_28days_95.rename(columns={'vonmises_time_28days_0.95' : 'lower_interval_28days_0.95'})\n",
    "train_data = pd.merge(train_data, low_28days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_28days_95 = train_data.set_index('Time').groupby(['CustomerId']).rolling('28d')['vonmises_time_28days_0.95'].apply(upper_interval_95)\n",
    "high_28days_95 = high_28days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_28days_95 = high_28days_95.rename(columns={'vonmises_time_28days_0.95' : 'upper_interval_28days_0.95'})\n",
    "train_data = pd.merge(train_data, high_28days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "train_data['lower_interval_28days_0.95'].fillna(train_data['lower_interval_28days_0.95'].mean(), inplace=True)\n",
    "train_data['upper_interval_28days_0.95'].fillna(train_data['upper_interval_28days_0.95'].mean(), inplace=True)\n",
    "\n",
    "train_data['Within_CI95_28days'] = train_data[['vonmises_time_28days_0.95', 'lower_interval_28days_0.95', 'upper_interval_28days_0.95']].apply(check, axis=1)\n",
    "\n",
    "train_data.drop(['mean_28days_0.95', 'std_28days_0.95', 'inv_std_28days_0.95', 'vonmises_time_28days_0.95', 'lower_interval_28days_0.95', 'upper_interval_28days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_mean_ProductCategory', 'Amount_to_std_ProductCategory',\n",
       "       'Amount_to_mean_ChannelId', 'Amount_to_std_ChannelId',\n",
       "       'Amount_to_mean_ProductId', 'Amount_to_std_ProductId',\n",
       "       'Within_CI95_7days', 'Within_CI95_14days', 'Within_CI95_21days',\n",
       "       'Within_CI95_28days'],\n",
       "      dtype='object', length=150)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     55670\n",
       "Yes    39992\n",
       "Name: Within_CI95_14days, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Within_CI95_14days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_7days_95 = test_data.set_index('Time').groupby('CustomerId').rolling('7d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_7days_95 = agg_func_7days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_7days_0.95', 'std' : 'std_7days_0.95'})\n",
    "test_data = pd.merge(test_data, agg_func_7days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['std_7days_0.95'] = test_data['std_7days_0.95'].fillna(0)\n",
    "test_data['inv_std_7days_0.95'] = 1/test_data['std_7days_0.95']\n",
    "test_data['inv_std_7days_0.95'] = test_data['inv_std_7days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "test_data['inv_std_7days_0.95'] = test_data['inv_std_7days_0.95'].fillna(0)\n",
    "\n",
    "test_data['vonmises_time_7days_0.95'] = test_data[['inv_std_7days_0.95', 'Time_in_Secs', 'mean_7days_0.95', 'std_7days_0.95']].apply(distribution, axis=1)\n",
    "test_data['vonmises_time_7days_0.95'].fillna(test_data['vonmises_time_7days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_7days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('7d')['vonmises_time_7days_0.95'].apply(lower_interval_95)\n",
    "low_7days_95 = low_7days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_7days_95 = low_7days_95.rename(columns={'vonmises_time_7days_0.95' : 'lower_interval_7days_0.95'})\n",
    "test_data = pd.merge(test_data, low_7days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_7days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('7d')['vonmises_time_7days_0.95'].apply(upper_interval_95)\n",
    "high_7days_95 = high_7days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_7days_95 = high_7days_95.rename(columns={'vonmises_time_7days_0.95' : 'upper_interval_7days_0.95'})\n",
    "test_data = pd.merge(test_data, high_7days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['lower_interval_7days_0.95'].fillna(test_data['lower_interval_7days_0.95'].mean(), inplace=True)\n",
    "test_data['upper_interval_7days_0.95'].fillna(test_data['upper_interval_7days_0.95'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_std_ChannelId', 'Amount_to_mean_ProductId',\n",
       "       'Amount_to_std_ProductId', 'mean_7days_0.95', 'std_7days_0.95',\n",
       "       'inv_std_7days_0.95', 'vonmises_time_7days_0.95',\n",
       "       'lower_interval_7days_0.95', 'upper_interval_7days_0.95',\n",
       "       'Within_CI95_7days'],\n",
       "      dtype='object', length=152)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Within_CI95_7days'] = test_data[['vonmises_time_7days_0.95', 'lower_interval_7days_0.95', 'upper_interval_7days_0.95']].apply(check, axis=1)\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    24076\n",
       "No     20943\n",
       "Name: Within_CI95_7days, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.drop(['mean_7days_0.95', 'std_7days_0.95', 'inv_std_7days_0.95', 'vonmises_time_7days_0.95', 'lower_interval_7days_0.95', 'upper_interval_7days_0.95'], axis=1, inplace=True)\n",
    "test_data['Within_CI95_7days'].value_counts()#.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_std_ProviderId', 'Amount_to_mean_PricingStrategy',\n",
       "       'Amount_to_std_PricingStrategy', 'Amount_to_mean_ProductCategory',\n",
       "       'Amount_to_std_ProductCategory', 'Amount_to_mean_ChannelId',\n",
       "       'Amount_to_std_ChannelId', 'Amount_to_mean_ProductId',\n",
       "       'Amount_to_std_ProductId', 'Within_CI95_7days'],\n",
       "      dtype='object', length=146)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_14days_95 = test_data.set_index('Time').groupby('CustomerId').rolling('14d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_14days_95 = agg_func_14days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_14days_0.95', 'std' : 'std_14days_0.95'})\n",
    "test_data = pd.merge(test_data, agg_func_14days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['std_14days_0.95'] = test_data['std_14days_0.95'].fillna(0)\n",
    "test_data['inv_std_14days_0.95'] = 1/test_data['std_14days_0.95']\n",
    "test_data['inv_std_14days_0.95'] = test_data['inv_std_14days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "test_data['inv_std_14days_0.95'] = test_data['inv_std_14days_0.95'].fillna(0)\n",
    "\n",
    "test_data['vonmises_time_14days_0.95'] = test_data[['inv_std_14days_0.95', 'Time_in_Secs', 'mean_14days_0.95', 'std_14days_0.95']].apply(distribution, axis=1)\n",
    "test_data['vonmises_time_14days_0.95'].fillna(test_data['vonmises_time_14days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_14days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('14d')['vonmises_time_14days_0.95'].apply(lower_interval_95)\n",
    "low_14days_95 = low_14days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_14days_95 = low_14days_95.rename(columns={'vonmises_time_14days_0.95' : 'lower_interval_14days_0.95'})\n",
    "test_data = pd.merge(test_data, low_14days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_14days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('14d')['vonmises_time_14days_0.95'].apply(upper_interval_95)\n",
    "high_14days_95 = high_14days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_14days_95 = high_14days_95.rename(columns={'vonmises_time_14days_0.95' : 'upper_interval_14days_0.95'})\n",
    "test_data = pd.merge(test_data, high_14days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['lower_interval_14days_0.95'].fillna(test_data['lower_interval_14days_0.95'].mean(), inplace=True)\n",
    "test_data['upper_interval_14days_0.95'].fillna(test_data['upper_interval_14days_0.95'].mean(), inplace=True)\n",
    "\n",
    "test_data['Within_CI95_14days'] = test_data[['vonmises_time_14days_0.95', 'lower_interval_14days_0.95', 'upper_interval_14days_0.95']].apply(check, axis=1)\n",
    "\n",
    "test_data.drop(['mean_14days_0.95', 'std_14days_0.95', 'inv_std_14days_0.95', 'vonmises_time_14days_0.95', 'lower_interval_14days_0.95', 'upper_interval_14days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_mean_PricingStrategy', 'Amount_to_std_PricingStrategy',\n",
       "       'Amount_to_mean_ProductCategory', 'Amount_to_std_ProductCategory',\n",
       "       'Amount_to_mean_ChannelId', 'Amount_to_std_ChannelId',\n",
       "       'Amount_to_mean_ProductId', 'Amount_to_std_ProductId',\n",
       "       'Within_CI95_7days', 'Within_CI95_14days'],\n",
       "      dtype='object', length=147)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     23516\n",
       "Yes    21503\n",
       "Name: Within_CI95_14days, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Within_CI95_14days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_21days_95 = test_data.set_index('Time').groupby('CustomerId').rolling('21d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_21days_95 = agg_func_21days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_21days_0.95', 'std' : 'std_21days_0.95'})\n",
    "test_data = pd.merge(test_data, agg_func_21days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['std_21days_0.95'] = test_data['std_21days_0.95'].fillna(0)\n",
    "test_data['inv_std_21days_0.95'] = 1/test_data['std_21days_0.95']\n",
    "test_data['inv_std_21days_0.95'] = test_data['inv_std_21days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "test_data['inv_std_21days_0.95'] = test_data['inv_std_21days_0.95'].fillna(0)\n",
    "\n",
    "test_data['vonmises_time_21days_0.95'] = test_data[['inv_std_21days_0.95', 'Time_in_Secs', 'mean_21days_0.95', 'std_21days_0.95']].apply(distribution, axis=1)\n",
    "test_data['vonmises_time_21days_0.95'].fillna(test_data['vonmises_time_21days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_21days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('21d')['vonmises_time_21days_0.95'].apply(lower_interval_95)\n",
    "low_21days_95 = low_21days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_21days_95 = low_21days_95.rename(columns={'vonmises_time_21days_0.95' : 'lower_interval_21days_0.95'})\n",
    "test_data = pd.merge(test_data, low_21days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_21days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('21d')['vonmises_time_21days_0.95'].apply(upper_interval_95)\n",
    "high_21days_95 = high_21days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_21days_95 = high_21days_95.rename(columns={'vonmises_time_21days_0.95' : 'upper_interval_21days_0.95'})\n",
    "test_data = pd.merge(test_data, high_21days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['lower_interval_21days_0.95'].fillna(test_data['lower_interval_21days_0.95'].mean(), inplace=True)\n",
    "test_data['upper_interval_21days_0.95'].fillna(test_data['upper_interval_21days_0.95'].mean(), inplace=True)\n",
    "\n",
    "test_data['Within_CI95_21days'] = test_data[['vonmises_time_21days_0.95', 'lower_interval_21days_0.95', 'upper_interval_21days_0.95']].apply(check, axis=1)\n",
    "\n",
    "test_data.drop(['mean_21days_0.95', 'std_21days_0.95', 'inv_std_21days_0.95', 'vonmises_time_21days_0.95', 'lower_interval_21days_0.95', 'upper_interval_21days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_std_PricingStrategy', 'Amount_to_mean_ProductCategory',\n",
       "       'Amount_to_std_ProductCategory', 'Amount_to_mean_ChannelId',\n",
       "       'Amount_to_std_ChannelId', 'Amount_to_mean_ProductId',\n",
       "       'Amount_to_std_ProductId', 'Within_CI95_7days', 'Within_CI95_14days',\n",
       "       'Within_CI95_21days'],\n",
       "      dtype='object', length=148)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     23516\n",
       "Yes    21503\n",
       "Name: Within_CI95_14days, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Within_CI95_21days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "agg_func_28days_95 = test_data.set_index('Time').groupby('CustomerId').rolling('28d')['Time_in_Secs'].agg([mn, std]).reset_index()\n",
    "agg_func_28days_95 = agg_func_28days_95.drop_duplicates(subset=['CustomerId', 'Time']).rename(columns={'mn' : 'mean_28days_0.95', 'std' : 'std_28days_0.95'})\n",
    "test_data = pd.merge(test_data, agg_func_28days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['std_28days_0.95'] = test_data['std_28days_0.95'].fillna(0)\n",
    "test_data['inv_std_28days_0.95'] = 1/test_data['std_28days_0.95']\n",
    "test_data['inv_std_28days_0.95'] = test_data['inv_std_28days_0.95'].replace([np.inf, -np.inf], np.nan)\n",
    "test_data['inv_std_28days_0.95'] = test_data['inv_std_28days_0.95'].fillna(0)\n",
    "\n",
    "test_data['vonmises_time_28days_0.95'] = test_data[['inv_std_28days_0.95', 'Time_in_Secs', 'mean_28days_0.95', 'std_28days_0.95']].apply(distribution, axis=1)\n",
    "test_data['vonmises_time_28days_0.95'].fillna(test_data['vonmises_time_28days_0.95'].mean(), inplace=True)\n",
    "\n",
    "low_28days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('28d')['vonmises_time_28days_0.95'].apply(lower_interval_95)\n",
    "low_28days_95 = low_28days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "low_28days_95 = low_28days_95.rename(columns={'vonmises_time_28days_0.95' : 'lower_interval_28days_0.95'})\n",
    "test_data = pd.merge(test_data, low_28days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "high_28days_95 = test_data.set_index('Time').groupby(['CustomerId']).rolling('28d')['vonmises_time_28days_0.95'].apply(upper_interval_95)\n",
    "high_28days_95 = high_28days_95.reset_index().drop_duplicates(subset=['CustomerId', 'Time'])\n",
    "high_28days_95 = high_28days_95.rename(columns={'vonmises_time_28days_0.95' : 'upper_interval_28days_0.95'})\n",
    "test_data = pd.merge(test_data, high_28days_95, on=['CustomerId', 'Time'], how='left')\n",
    "\n",
    "test_data['lower_interval_28days_0.95'].fillna(test_data['lower_interval_28days_0.95'].mean(), inplace=True)\n",
    "test_data['upper_interval_28days_0.95'].fillna(test_data['upper_interval_28days_0.95'].mean(), inplace=True)\n",
    "\n",
    "test_data['Within_CI95_28days'] = test_data[['vonmises_time_28days_0.95', 'lower_interval_28days_0.95', 'upper_interval_28days_0.95']].apply(check, axis=1)\n",
    "\n",
    "test_data.drop(['mean_28days_0.95', 'std_28days_0.95', 'inv_std_28days_0.95', 'vonmises_time_28days_0.95', 'lower_interval_28days_0.95', 'upper_interval_28days_0.95'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Amount',\n",
       "       ...\n",
       "       'Amount_to_mean_ProductCategory', 'Amount_to_std_ProductCategory',\n",
       "       'Amount_to_mean_ChannelId', 'Amount_to_std_ChannelId',\n",
       "       'Amount_to_mean_ProductId', 'Amount_to_std_ProductId',\n",
       "       'Within_CI95_7days', 'Within_CI95_14days', 'Within_CI95_21days',\n",
       "       'Within_CI95_28days'],\n",
       "      dtype='object', length=149)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     23994\n",
       "Yes    21025\n",
       "Name: Within_CI95_28days, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Within_CI95_28days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Amount</th>\n",
       "      <th>...</th>\n",
       "      <th>Amount_to_mean_ProductCategory</th>\n",
       "      <th>Amount_to_std_ProductCategory</th>\n",
       "      <th>Amount_to_mean_ChannelId</th>\n",
       "      <th>Amount_to_std_ChannelId</th>\n",
       "      <th>Amount_to_mean_ProductId</th>\n",
       "      <th>Amount_to_std_ProductId</th>\n",
       "      <th>Within_CI95_7days</th>\n",
       "      <th>Within_CI95_14days</th>\n",
       "      <th>Within_CI95_21days</th>\n",
       "      <th>Within_CI95_28days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95657</th>\n",
       "      <td>TransactionId_89881</td>\n",
       "      <td>BatchId_96668</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_3078</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087447</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>-0.072763</td>\n",
       "      <td>1.106786</td>\n",
       "      <td>-0.556767</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95658</th>\n",
       "      <td>TransactionId_91597</td>\n",
       "      <td>BatchId_3503</td>\n",
       "      <td>AccountId_3439</td>\n",
       "      <td>SubscriptionId_2643</td>\n",
       "      <td>CustomerId_3874</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.215131</td>\n",
       "      <td>0.043294</td>\n",
       "      <td>0.073433</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.611768</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95659</th>\n",
       "      <td>TransactionId_82501</td>\n",
       "      <td>BatchId_118602</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_3874</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>-0.001455</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>-0.011135</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95660</th>\n",
       "      <td>TransactionId_136354</td>\n",
       "      <td>BatchId_70924</td>\n",
       "      <td>AccountId_1346</td>\n",
       "      <td>SubscriptionId_652</td>\n",
       "      <td>CustomerId_1709</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_19</td>\n",
       "      <td>tv</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180276</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>0.220299</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.460657</td>\n",
       "      <td>0.496177</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95661</th>\n",
       "      <td>TransactionId_35670</td>\n",
       "      <td>BatchId_29317</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_1709</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005247</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>-0.004366</td>\n",
       "      <td>0.066407</td>\n",
       "      <td>-0.033406</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              TransactionId         BatchId       AccountId  \\\n",
       "95657   TransactionId_89881   BatchId_96668  AccountId_4841   \n",
       "95658   TransactionId_91597    BatchId_3503  AccountId_3439   \n",
       "95659   TransactionId_82501  BatchId_118602  AccountId_4841   \n",
       "95660  TransactionId_136354   BatchId_70924  AccountId_1346   \n",
       "95661   TransactionId_35670   BatchId_29317  AccountId_4841   \n",
       "\n",
       "            SubscriptionId       CustomerId    ProviderId     ProductId  \\\n",
       "95657  SubscriptionId_3829  CustomerId_3078  ProviderId_4   ProductId_6   \n",
       "95658  SubscriptionId_2643  CustomerId_3874  ProviderId_6  ProductId_10   \n",
       "95659  SubscriptionId_3829  CustomerId_3874  ProviderId_4   ProductId_6   \n",
       "95660   SubscriptionId_652  CustomerId_1709  ProviderId_6  ProductId_19   \n",
       "95661  SubscriptionId_3829  CustomerId_1709  ProviderId_4   ProductId_6   \n",
       "\n",
       "          ProductCategory    ChannelId  Amount  ...  \\\n",
       "95657  financial_services  ChannelId_2 -1000.0  ...   \n",
       "95658             airtime  ChannelId_3  1000.0  ...   \n",
       "95659  financial_services  ChannelId_2   -20.0  ...   \n",
       "95660                  tv  ChannelId_3  3000.0  ...   \n",
       "95661  financial_services  ChannelId_2   -60.0  ...   \n",
       "\n",
       "      Amount_to_mean_ProductCategory  Amount_to_std_ProductCategory  \\\n",
       "95657                      -0.087447                      -0.005666   \n",
       "95658                       1.215131                       0.043294   \n",
       "95659                      -0.001749                      -0.000113   \n",
       "95660                       0.180276                       0.071339   \n",
       "95661                      -0.005247                      -0.000340   \n",
       "\n",
       "       Amount_to_mean_ChannelId  Amount_to_std_ChannelId  \\\n",
       "95657                  0.256410                -0.072763   \n",
       "95658                  0.073433                 0.006297   \n",
       "95659                  0.005128                -0.001455   \n",
       "95660                  0.220299                 0.018892   \n",
       "95661                  0.015385                -0.004366   \n",
       "\n",
       "       Amount_to_mean_ProductId  Amount_to_std_ProductId Within_CI95_7days  \\\n",
       "95657                  1.106786                -0.556767               Yes   \n",
       "95658                  0.611768                 0.033770                No   \n",
       "95659                  0.022136                -0.011135                No   \n",
       "95660                  0.460657                 0.496177                No   \n",
       "95661                  0.066407                -0.033406                No   \n",
       "\n",
       "      Within_CI95_14days  Within_CI95_21days Within_CI95_28days  \n",
       "95657                 No                  No                 No  \n",
       "95658                 No                  No                 No  \n",
       "95659                 No                  No                 No  \n",
       "95660                 No                  No                 No  \n",
       "95661                 No                  No                 No  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_data[['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId']]\n",
    "test_ids = test_data[['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId']]\n",
    "\n",
    "train_ids.to_csv('trainIds.csv', index=False)\n",
    "test_ids.to_csv('testIds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', \n",
    "                 'TransactionStartTime', 'Past_one_Week', 'Date'], \n",
    "                axis=1, inplace=True\n",
    "               )\n",
    "\n",
    "testTransId = test_data['TransactionId']\n",
    "test_data.drop(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', \n",
    "                 'TransactionStartTime', 'Past_one_Week', 'Date'], \n",
    "                axis=1, inplace=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Time', axis=1, inplace=True)\n",
    "test_data.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Year']\n",
    "\n",
    "for col in cat_columns:\n",
    "    train_data[col] = train_data[col].astype(str)\n",
    "    test_data[col] = test_data[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Hour', axis=1, inplace=True)\n",
    "test_data.drop('Hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95662, 140)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45019, 139)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Year',\n",
       "       'Month', 'Weekday', 'Weekday/Weekend', 'Holiday', 'Form', 'Suspicious',\n",
       "       'Multiple_Sub_by_Customer', 'Multiple_Sub_by_Acc', 'Week',\n",
       "       'Within_CI95_7days', 'Within_CI95_14days', 'Within_CI95_21days',\n",
       "       'Within_CI95_28days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Amount', 'PricingStrategy', 'FraudResult', 'No. Customers per Acc',\n",
       "       'ExtraCharges', 'Days_to_Nearest_Holiday', 'Prev_Amt',\n",
       "       'Time_since_last_trans', 'Avg_amt_per_ProviderId_in_last_12hhrs',\n",
       "       'sum_of_amt_per_ProviderId_in_last_12hhrs',\n",
       "       ...\n",
       "       'Amount_to_mean_ProviderId', 'Amount_to_std_ProviderId',\n",
       "       'Amount_to_mean_PricingStrategy', 'Amount_to_std_PricingStrategy',\n",
       "       'Amount_to_mean_ProductCategory', 'Amount_to_std_ProductCategory',\n",
       "       'Amount_to_mean_ChannelId', 'Amount_to_std_ChannelId',\n",
       "       'Amount_to_mean_ProductId', 'Amount_to_std_ProductId'],\n",
       "      dtype='object', length=122)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "fraudResult = train_data['FraudResult']\n",
    "\n",
    "train_num = train_data.drop('FraudResult', axis=1).select_dtypes(exclude='object')\n",
    "test_num = test_data.select_dtypes(exclude='object')\n",
    "\n",
    "train_cat = train_data.select_dtypes(include='object')\n",
    "test_cat = test_data.select_dtypes(include='object')\n",
    "\n",
    "train_cat['label'] = 1\n",
    "test_cat['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train_cat, test_cat], axis=0)#.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=combined.columns[:-1], drop_first=True)\n",
    "\n",
    "train_cat = combined[combined['label']==1]\n",
    "test_cat = combined[combined['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_cat.drop('label', axis=1, inplace=True)\n",
    "test_cat.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_num, train_cat, fraudResult], axis=1)\n",
    "test_data = pd.concat([test_num, test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(train_data.isnull().sum()>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45019, 191)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('FinalTrain31Aug.csv', index=False)\n",
    "test_data.to_csv('FinalTest31Aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testTransId.to_csv('testTransId.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
